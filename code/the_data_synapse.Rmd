# Run some basic smoothing on a timeseries

## Climate data simulation

Example of simulated climate data. This has a general (quadratic) trend with an auto-regressive noise model on top. Multiple replicates are returned, with randomly assigned trend parameters assigned.

```{r, timeseries_smoothing}

#' Generate some toy climate timeseries
#' 
#' @param arg_vals_days Vector (numeric). The timepoints for evaluation.
#' @param num_reps Numeric. Number of different timeseries.
#' @param mean_of_noise Numeric. Mean of noise (within ARIMA model).
#' @param spread_trends Numeric. Spread of the trends about 0.
#' @param spread_consts Numeric. Spread of the const values about 40.
generate_toy_climate_data <- function(
  arg_vals_days = 1:(2*365),
  num_reps = 2,
  mean_of_noise = 0.02,
  spread_trends = 5,
  const_avg = 100,
  spread_consts = 10,
  seed_in = 123
){
  set.seed(seed_in)  # for reproducibility
  trends = runif(num_reps, min = -spread_trends, max = spread_trends)
  consts = runif(num_reps, min = const_avg - spread_consts, max = const_avg + spread_consts)
  
  eg_df <- data.frame(matrix(nrow = length(arg_vals_days),
                             ncol = num_reps))
  colnames(eg_df) <- 1:num_reps
  
  for (j in 1:num_reps) {
    eg_fluc_data <- sapply(
      arg_vals_days,
      function(i) {
        consts[j] + trends[j]*(i/365)**3 + 5*cos(i*2*pi/365) + 0.3 * sin(i*pi/3)
      }
    ) + arima.sim(
      length(arg_vals_days),
      mean = mean_of_noise,
      model = list(order = c(1,0,0), ar = 0.9)
    )
    eg_df[, j] <- eg_fluc_data
  }
  return(eg_df)
}

arg_vals_days <- 1:(5*365)
example_data <- generate_toy_climate_data(
  arg_vals_days = arg_vals_days,
  num_reps = 5,
  spread_trends = 0.8,
  spread_consts = 10
)

matplot(
  example_data, 
  type = 'l', 
  col = 1:5, 
  lty = 1,
  main = "Examples of simulated timeseries",
  xlab = "Time (days)",
  ylab = "Value"
)
```

Next, provide the user options to smooth the data. This consists of different basis function types and options for the amount of smoothing of the data.

```{r,create_funcs}
#' Fit a spline to a collection of timeseries, with a possible roughness penalty
#'
#' @param data_to_smooth A data frame. Rows correspond to different time points
#' and columns correspond to different variables.
#' @param timepoints A vector (numeric). Corresponds to the measurement 
#' timepoints of each variable.
#' @param nbasis_in Integer. The number of basis functions to use.
#' @param lambda_in Float. Defaults to 0. The value of the smoothing parameter,
#' lambda.
#' @param basis_type String. Defaults to "fourier". Can be either "fourier" or
#' "bspline" to select different families of basis functions.
#' @param norder_in Integer. Defaults to 4. Only relevant if basis_type = 
#' TRUE. Controls the order of the bspline functions.
#'
#' @return An fdSmooth object.
fits_from_params <- function(data_to_smooth,
                             timepoints,
                             nbasis_in,
                             lambda_in = 0,
                             basis_type = "fourier",
                             norder_in = 4) {
  range_of_timeseries <- c(min(timepoints), max(timepoints))
  
  penalty_basis <- switch(
    basis_type,
    fourier = fda::create.fourier.basis(
      rangeval = range_of_timeseries,
      nbasis = nbasis_in,
      
    ),
    bspline = fda::create.bspline.basis(
      rangeval = range_of_timeseries,
      nbasis = nbasis_in,
      norder = norder_in
    )
  )
  
  if (is.null(penalty_basis)) {
    stop('basis_type not recognised - must be "fourier" or "bspline"')
  }
  
  
  # Define a linear differential operator
  second_deriv_operator = fda::int2Lfd(2)
  
  fd_params = fda::fdPar(penalty_basis, second_deriv_operator, lambda_in)
  fd_outputs = fda::smooth.basis(
    timepoints,
    data_to_smooth, 
    fd_params
  )
  
  return(fd_outputs)
  
}
```

Here are some specific examples of 'smoothed' output data. The user would be expected to select an appropriate smoothing by eye. (In general, there is no algorithmic approach to smooth a function perfectly and this is extremely variable depending on the dataset!)

```{r, smooth}
basic_output_fits <- fits_from_params(
  as.matrix(example_data),
  arg_vals_days,
  20,
  lambda_in = 50,
  basis_type = "bspline"
)

png("../results/good_timeseries_fits.png", width = 600, height = 500, pointsize = 16)
matplot(example_data, type = 'l', col = 1:5, lty = 1,
        main = "Examples of fits to timeseries",
        xlab = "Time (days)",
        ylab = "Value")
lines(basic_output_fits, 
      col = 1:5,
      lty = 1)
dev.off()
```
Be aware - this can go wrong easily!

```{r, smooth_bad}
basic_output_fits_bad <- fits_from_params(
  as.matrix(example_data),
  arg_vals_days,
  8,
  lambda_in = 500,
  basis_type = "bspline"
)

png("../results/bad_timeseries_fits.png", width = 600, height = 500, pointsize = 16)
matplot(example_data, type = 'l', col = 1:5, lty = 1,
        main = "Poor fits to timeseries",
        xlab = "Time (days)",
        ylab = "Value")
lines(basic_output_fits_bad, 
      col = 1:5,
      lty = 1)
dev.off()
```

You can also smooth this data by taking the rolling average, as a pre-processing step before smoothing:

```{r, rolling_average}
# apply rollmean to each column, which contains an independent replicate
rolling_data <- apply(example_data, 2, function(col_in) {
  zoo::rollmean(col_in, k = 100)
})

matplot(rolling_data, type = 'l', col = 1:5, lty = 1,
        main = "Rolling average of timeseries",
        xlab = "Time (days)",
        ylab = "Value")
```

## Simulating economic data

For now, we can simulate some economic data by taking subsets of the climate data at specific timepoints.

```{r, simulate_economic_data}

#' Takes an fd object (from FDA package), which  is assumed to be a densely timeseries, and produces a noisy and sparse subsample.
#'
#' @param climate_timeseries_fd fd object. The smoothed timeseries to manipulate into producing a sampled timeseries.
#' @param time_vec Numeric vector. Corresponds to the timepoints of climate_timeseries_fd to predict. NOTE: that the dataset will be manipulated and then sparsely sampled to match this.
#' @param x_stretch Numeric. The amount the 'stretch' the timeseries in the x (time) direction. For example, asking for timepoints 0, 2, 4 and asking for an x-stretch of 1/2 would actually sample timepoints 0, 1, 2.
#' @param y_stretch Numeric. The amount the 'stretch' the timeseries in the y (output) direction.
#' @param noise_level Numeric. The standard deviation of ARIMA model noise added in addition to the sampling.
reduce_climate_to_sparse <- function(climate_timeseries_fd,
                                     time_vec,
                                     which_rep = 1,
                                     x_stretch = 1,
                                     y_stretch = 1,
                                     noise_level = 1e-2) {
  
  # do x-shift
  min_time <- min(time_vec)
  max_time <- max(time_vec)
  freq_timeseries <- seq(min_time, max_time, length.out = 1000)
  new_eval_points <- (freq_timeseries - min_time) * x_stretch + min_time
  output_data <- fda::eval.fd(new_eval_points, climate_timeseries_fd)[, which_rep]
  
  # do y-shift
  output_data <- (output_data - min(output_data)) * y_stretch + min(output_data)
  
  # add noise
  output_data <- output_data + rnorm(length(output_data), sd = noise_level)
  
  # return evenly spaced timepoints
  sparse_sampling_pts <- seq(
    from = 1, 
    to = length(output_data),
    length.out = length(time_vec)
  )
  
  return(output_data[sparse_sampling_pts])
}
```

## Example of searching the dataset

This has an advantage over other distance metrics, such as the standard Euclidean distance metric, as these often make incorrect assumptions about timeseries. For example, if a timeseries has a lag, the standard Euclidean distance can be large, despite the two curves having the same shape. A 'shape-based' metric may be much more effective at spotting similarities between shifted timeseries.

In order to compare the densely-sample timeseries with the sparse one, we first need to subsample our approximation of the timeseries.

[Dynamic Time Warping](https://en.wikipedia.org/wiki/Dynamic_time_warping) provides a method to compares two timeseries, which allows for realistic "stretching" of one timeseries against another. Additionally, as a dynamic programming algorithm, it is possible to search for a subset of a fit within the data.

``` {r, example_of_sparse_sampler}
sparse_climate_tps <- seq(from = 1, to = 5*365, by = 100)
full_evaluated_seq <- fda::eval.fd(sparse_climate_tps, basic_output_fits$fd)[,1]

sparse_tps <- seq(from = 366, to = 4*365, by = 100)
eg_econ_data_full <- reduce_climate_to_sparse(
  basic_output_fits[1]$fd,
  sparse_tps,
  x_stretch = 1,
  y_stretch = 1.1,
  noise_level = 0.1
)

eg_econ_data_short <- reduce_climate_to_sparse(
  basic_output_fits[1]$fd,
  sparse_tps,
  x_stretch = 1/2,
  noise_level = 1e-2
)

set.seed(123)
spread_of_negative_control <- sd(eg_econ_data_short) / 10
eg_uncorrelated_timeseries <- rep(c(-5, 15, 0, -5, 5), length.out = length(sparse_tps)) +
  rnorm(n = length(sparse_tps),
  mean = mean(eg_econ_data_short),
  sd = spread_of_negative_control)


plot(sparse_climate_tps, full_evaluated_seq, type = "l", ylim = c(50, 105),
     xlab = "Time (days)", ylab = "Value", main = "All plots")
lines(arg_vals_days, example_data[,1], col = "grey")
lines(sparse_tps + 400, eg_econ_data_full, type = "l", col = "purple", lwd = 2)
lines(sparse_tps, eg_econ_data_short, type = "l", col = "red", lwd = 2)
lines(sparse_tps, eg_uncorrelated_timeseries, type = "l", col = "darkgreen", lty = "dashed", lwd = 2)
```
``` {r, compare_short_climate}
eg_econ_full_dtw <- dtw::dtw(
  eg_econ_data_full,
  full_evaluated_seq,
  open.end = TRUE,
  open.begin = TRUE,
  step.pattern = dtw::asymmetricP05
)
print(paste0("Distance from black to purple: ", eg_econ_full_dtw$normalizedDistance))

eg_econ_short_dtw <- dtw::dtw(
  eg_econ_data_short,
  full_evaluated_seq,
  open.end = TRUE,
  open.begin = TRUE,
  step.pattern = dtw::asymmetric
)
print(paste0("Distance from black to red: ", eg_econ_short_dtw$normalizedDistance))

eg_uncor_dtw <- dtw::dtw(
  eg_uncorrelated_timeseries,
  full_evaluated_seq,
  open.end = TRUE,
  open.begin = TRUE,
  step.pattern = dtw::asymmetric
)
print(paste0("Distance from black to green: ", eg_uncor_dtw$normalizedDistance))
```


``` {r, separate_plots}
png("../results/shifted.png", pointsize = 16, width = 700, height = 500)
plot(sparse_climate_tps, full_evaluated_seq, type = "l", ylim = c(50, 105),
     xlab = "Time (days)", ylab = "Value", main = "Shifted timeseries")
lines(arg_vals_days, example_data[,1], col = "grey")
lines(sparse_tps + 400, eg_econ_data_full, type = "l", col = "purple", lwd = 2)
text(230, 54, paste0("DTW distance = ", sprintf("%.2f",  eg_econ_full_dtw$normalizedDistance)))
dev.off()

png("../results/scaled.png", pointsize = 16, width = 700, height = 500)
plot(sparse_climate_tps, full_evaluated_seq, type = "l", ylim = c(50, 105),
     xlab = "Time (days)", ylab = "Value", main = "Misaligned peaks")
lines(arg_vals_days, example_data[,1], col = "grey")
lines(sparse_tps, eg_econ_data_short, type = "l", col = "red", lwd = 2)
text(230, 54, paste0("DTW distance = ", sprintf("%.2f",  eg_econ_short_dtw$normalizedDistance)))
dev.off()

png("../results/uncorrelated.png", pointsize = 16, width = 700, height = 500)
plot(sparse_climate_tps, full_evaluated_seq, type = "l", ylim = c(50, 105),
     xlab = "Time (days)", ylab = "Value", main = "No correlation")
lines(arg_vals_days, example_data[,1], col = "grey")
lines(sparse_tps, eg_uncorrelated_timeseries, type = "l", col = "darkgreen", lty = "dashed", lwd = 2)
text(230, 54, paste0("DTW distance = ", sprintf("%.2f",  eg_uncor_dtw$normalizedDistance)))
dev.off()
```

